#!/usr/bin/env python3
"""merge_and_engineer.py

Read converted CSVs from data/raw/<cycle>/csv/, harmonize, merge on SEQN, create target and features,
and write data/processed/merged_clean.csv
"""

import os, sys, glob, json
from pathlib import Path
import pandas as pd
import numpy as np
import argparse

# --- Config ---
CYCLES = [
    "2005_2006",
    "2007_2008",
    "2009_2010",
    "2011_2012",
    "2013_2014",
    "2015_2016",
]

CSV_DIR_TEMPLATE = \"{root}/{cycle}/csv\"\n\nFEATURE_COLS = [\n    'age', 'sex', 'BMI', 'exercise_min_week',\n    'calories_day', 'fiber_g_day', 'added_sugar_g_day', 'caffeine_mg_day',\n    'alcohol_drinks_week', 'current_smoker', 'depression_score',\n    'systolic_bp', 'diastolic_bp'\n]\n\ndef safe_read_csv(path):\n    try:\n        return pd.read_csv(path, low_memory=False)\n    except Exception as e:\n        print(f\"Could not read {path}: {e}\")\n        return None\n\ndef harmonize_and_merge(root):\n    dfs = []\n    for cycle in CYCLES:\n        csv_dir = CSV_DIR_TEMPLATE.format(root=root, cycle=cycle)\n        if not os.path.isdir(csv_dir):\n            print(f\"Skipping missing cycle folder: {csv_dir}\")\n            continue\n        # read files if present\n        files = os.listdir(csv_dir)\n        # Try to load common tables into dict\n        table_map = {}\n        for f in files:\n            name = f.upper()\n            if 'DEMO' in name:\n                table_map['DEMO'] = safe_read_csv(os.path.join(csv_dir, f))\n            elif 'SLQ' in name:\n                table_map['SLQ'] = safe_read_csv(os.path.join(csv_dir, f))\n            elif 'PAQ' in name:\n                table_map['PAQ'] = safe_read_csv(os.path.join(csv_dir, f))\n            elif 'DR1TOT' in name:\n                table_map['DR1TOT'] = safe_read_csv(os.path.join(csv_dir, f))\n            elif 'DR2TOT' in name:\n                table_map['DR2TOT'] = safe_read_csv(os.path.join(csv_dir, f))\n            elif 'BMX' in name:\n                table_map['BMX'] = safe_read_csv(os.path.join(csv_dir, f))\n            elif 'BPX' in name:\n                table_map['BPX'] = safe_read_csv(os.path.join(csv_dir, f))\n            elif 'DPQ' in name:\n                table_map['DPQ'] = safe_read_csv(os.path.join(csv_dir, f))\n            elif 'ALQ' in name:\n                table_map['ALQ'] = safe_read_csv(os.path.join(csv_dir, f))\n            elif 'SMQ' in name:\n                table_map['SMQ'] = safe_read_csv(os.path.join(csv_dir, f))\n        if 'DEMO' not in table_map:\n            print(f\"Cycle {cycle} missing DEMO -> skipping\")\n            continue\n        # merge progressively on SEQN\n        df = table_map['DEMO']\n        # ensure SEQN exists\n        if 'SEQN' not in df.columns:\n            print(f\"DEMO in {cycle} missing SEQN, skipping\")\n            continue\n        for key in ['SLQ','PAQ','DR1TOT','DR2TOT','BMX','BPX','DPQ','ALQ','SMQ']:\n            if key in table_map and table_map[key] is not None:\n                t = table_map[key]\n                if 'SEQN' in t.columns:\n                    df = df.merge(t, on='SEQN', how='left')\n        df['cycle'] = cycle\n        dfs.append(df)\n    if not dfs:\n        raise RuntimeError('No cycles loaded')\n    big = pd.concat(dfs, ignore_index=True, sort=False)\n    return big\n\n# target creation\n\ndef create_sleep_disorder_label(row):\n    # 1) Doctor-diagnosed sleep disorder (SLQ060 if present)\n    if pd.notna(row.get('SLQ060')) and row.get('SLQ060') == 1:\n        return 1\n    # 2) Short or long sleep (SLD012)\n    try:\n        sh = row.get('SLD012')\n        if pd.notna(sh):\n            shf = float(sh)\n            if shf < 7 or shf > 9:\n                return 1\n            if 7 <= shf <= 9:\n                return 0\n    except Exception:\n        pass\n    # 3) Frequent sleepiness (SLQ120 >= 16)\n    try:\n        if pd.notna(row.get('SLQ120')) and float(row.get('SLQ120')) >= 16:\n            return 1\n    except Exception:\n        pass\n    return np.nan\n\n# feature engineering\n\ndef engineer_features(df):\n    out = pd.DataFrame()\n    out['SEQN'] = df['SEQN']\n    out['cycle'] = df['cycle']\n    out['age'] = df.get('RIDAGEYR')\n    out['sex'] = df.get('RIAGENDR')\n    out['BMI'] = df.get('BMXBMI')\n    # exercise: PAD680 (moderate), PAD700 (vigorous)\n    pad680 = df.get('PAD680', 0).fillna(0) if 'PAD680' in df else 0\n    pad700 = df.get('PAD700', 0).fillna(0) if 'PAD700' in df else 0\n    # if columns are scalars, convert\n    if isinstance(pad680, (int, float)):\n        pad680 = pd.Series([pad680]*len(df))\n    if isinstance(pad700, (int, float)):\n        pad700 = pd.Series([pad700]*len(df))\n    try:\n        out['exercise_min_week'] = pad680.fillna(0) + pad700.fillna(0) * 2\n    except Exception:\n        out['exercise_min_week'] = 0\n    # diet: average of DR1/DR2 totals if present\n    def mean_col(df, cols):\n        present = [c for c in cols if c in df.columns]\n        if not present:\n            return pd.Series([pd.NA]*len(df))\n        return df[present].mean(axis=1)\n    out['calories_day'] = mean_col(df, ['DR1TKCAL','DR2TKCAL'])\n    out['fiber_g_day'] = mean_col(df, ['DR1TFIBE','DR2TFIBE'])\n    out['added_sugar_g_day'] = mean_col(df, ['DR1TSUGR','DR2TSUGR'])\n    out['caffeine_mg_day'] = mean_col(df, ['DR1TCAFF','DR2TCAFF'])\n    # alcohol\n    if 'ALQ130' in df.columns:\n        out['alcohol_drinks_week'] = df['ALQ130'].astype(float).fillna(0) * 7\n    else:\n        out['alcohol_drinks_week'] = 0\n    # smoking\n    if 'SMQ040' in df.columns:\n        out['current_smoker'] = (df['SMQ040'].apply(lambda x: 1 if (pd.notna(x) and (x<=2)) else 0)).astype('Int64')\n    else:\n        out['current_smoker'] = 0\n    # depression PHQ\n    phq_cols = [c for c in df.columns if c and str(c).upper().startswith('DPQ0')]\n    if phq_cols:\n        out['depression_score'] = df[phq_cols].sum(axis=1, min_count=len(phq_cols))\n    else:\n        out['depression_score'] = pd.Series([pd.NA]*len(df))\n    # BP\n    out['systolic_bp'] = df.get('BPXSY1')\n    out['diastolic_bp'] = df.get('BPXDI1')\n    # target\n    out['SLQ060'] = df.get('SLQ060')\n    out['SLD012'] = df.get('SLD012')\n    out['SLQ120'] = df.get('SLQ120')\n    out['sleep_disorder'] = df.apply(create_sleep_disorder_label, axis=1)\n    return out\n\n\ndef main(args):\n    root = args.input\n    out_dir = Path(args.output)\n    out_dir.parent.mkdir(parents=True, exist_ok=True)\n    big = harmonize_and_merge(root)\n    print(f\"Merged dataframe shape: {big.shape}\")\n    eng = engineer_features(big)\n    print(f\"Engineered features shape: {eng.shape}\")\n    # keep only feature cols + target\n    keep = ['SEQN','cycle'] + FEATURE_COLS + ['sleep_disorder']\n    for c in keep:\n        if c not in eng.columns:\n            eng[c] = pd.NA\n    out_df = eng[keep]\n    out_df.to_csv(out_dir, index=False)\n    print(f\"Wrote merged cleaned CSV to {out_dir}\")\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--input', default='data/raw', help='Root raw directory where cycles live')\n    parser.add_argument('--output', default='data/processed/merged_clean.csv', help='Output CSV')\n    args = parser.parse_args()\n    main(args)\n
